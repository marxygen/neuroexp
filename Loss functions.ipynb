{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b412f63",
   "metadata": {},
   "source": [
    "# Loss functions\n",
    "Loss functions are functions that allow us to assess the model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb25eeb",
   "metadata": {},
   "source": [
    "## Categorical Crossentropy\n",
    "This function is used to compare a ground truth probability and some predicted distribution. It is applied to a sample.\n",
    "Essentially it compares the desired result with the one provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b07f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d1604c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have the following distribution (softmax)\n",
    "softmax_output = [0.7, 0.1, 0.2]\n",
    "# ... and the desired prediction is\n",
    "desired_output = [0.9, 0.05, 0.05]\n",
    "# ..., so the first label is the correct one (vectors like this are called one-hot vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7b38025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(result: list, desired: list):\n",
    "    return -sum([desired[j] * log(result[j]) for j in range(len(desired))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d8898d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.5166085998162665\n"
     ]
    }
   ],
   "source": [
    "loss = cross_entropy(softmax_output, desired_output)\n",
    "print('Loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fece8e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35667494393873245\n"
     ]
    }
   ],
   "source": [
    "# With categorical cross entropy, we need to determine ONE class the given input belongs to, so we have the following\n",
    "# probabilities:\n",
    "desired = [0, 1, 0, 0]\n",
    "# The one-hot vector above indicates, that the given input belongs to label with index 1 (0-based)\n",
    "# If we want to determine the category, we're interested in the accuracy of the prediction of specific class, so we can\n",
    "# slightly modify the function to validate only the answer we're interested in\n",
    "# Say, the model has three outputs:\n",
    "# the first one says whether it's a dog, the second one - a cat, and the third one - a human\n",
    "# So, the model outputs something like [0.3, 0.5, 0.1], which indicates that the model thinks it's whatever comes second\n",
    "# in the list - in our case - a cat. Our answer says that it is indeed a cat - [0, 1, 0] (the desired output, the model\n",
    "# clearly sees a cat and doesn't see a dog or a human). 0 at `desired` index will make the products zero (see the formula\n",
    "# above), so we can just discard them. The one thing we'll have to know is THE INDEX OF THE CORRECT CHOICE.\n",
    "# In our case - 1 (0-based)\n",
    "def categorical_cross_entropy(result: list, desired_class_index: int):\n",
    "    return -log(result[desired_class_index])\n",
    "\n",
    "print(categorical_cross_entropy(softmax_output, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba272a7",
   "metadata": {},
   "source": [
    "We need to modify this function to work on batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09554d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first output - probability that it's a dog\n",
    "# The second output - probability that it's a cat\n",
    "# The third output - probability that it's a human\n",
    "softmax_outputs = np.array([\n",
    "    [0.7, 0.1, 0.2],\n",
    "    [0.1, 0.5, 0.4],\n",
    "    [0.02, 0.9, 0.08]\n",
    "])\n",
    "\n",
    "class_targets = [0, 1, 1] # Dog - 0, cat - 1, human - 3. These are the INDICES of answers for the three inputs (rows)\n",
    "class_targets = np.array([\n",
    "                            [1, 0, 0],\n",
    "                            [0, 1, 0],\n",
    "                            [0, 1, 0]]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a05ad070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_cross_entropy(predicted, correct):\n",
    "    # Number of samples in a batch\n",
    "    samples = len(predicted)\n",
    "    # Clip data to prevent division by 0\n",
    "    # Clip both sides to not drag mean towards any value\n",
    "    predicted_clipped = np.clip(predicted, 1e-7, 1 - 1e-7)\n",
    "    # Probabilities for target values -\n",
    "    # only if categorical labels\n",
    "    if len(correct.shape) == 1:\n",
    "        correct_confidences = predicted_clipped[\n",
    "        range(samples),\n",
    "        correct\n",
    "        ]\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "    elif len(correct.shape) == 2:\n",
    "        correct_confidences = np.sum(\n",
    "        predicted_clipped * correct,\n",
    "        axis=1\n",
    "        )\n",
    "    # Losses\n",
    "    negative_log_likelihoods = -np.log(correct_confidences)\n",
    "    return np.mean(negative_log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d21ab5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38506088005216804"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cross_entropy(softmax_outputs, class_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcb2b2a",
   "metadata": {},
   "source": [
    "## Calculating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d77bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_targets = np.array([0, 1, 1])\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    # Calculate values along second axis (axis of index 1)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    # If targets are one-hot encoded - convert them\n",
    "    if len(class_targets.shape) == 2:\n",
    "        targets = np.argmax(targets, axis=1)\n",
    "    # True evaluates to 1; False to 0\n",
    "    return np.mean(predictions==targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130337f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
